{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latent Dirichlet Allocation (LDA)\n",
    "\n",
    "## Main Idea\n",
    "The main idea behind Latent Dirichlet Allocation (LDA) is to provide a generative model for explaining the relationship between observations due to some unobserved entities. The best analogy is to say that a document contains certain topics, and the observed words in the document belong to one of the particular topics. Further, the words in a document are related to each other by their topic. Words are observed, the topics are generally unobserved or perhaps implicit. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topics in LDA\n",
    "\n",
    "\n",
    "Generally, a topic is a distribution over words.\n",
    "\n",
    "A topic is not strongly defined, neither semantically nor epistemologically. It is identified on the basis of supervised labeling and (manual) pruning on the basis of their likelihood of co-occurrence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters\n",
    "\n",
    "$ \\alpha: $ known hyperparameter for proportions. It governs the sparsity of distribution.\n",
    "\n",
    "$ \\eta $: known hyperparameter for topics\n",
    "\n",
    "$ K $: number of topics\n",
    "\n",
    "It is suggested to set these to 0.3 and consider the values as given (do not motivate them)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alpha = 0.3\n",
    "eta = 0.3\n",
    "num_topics = 3 #K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Documents, Vocabulary, Importing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is imported, where each element in the array represents a document\n",
    "\n",
    "Words are imported where each word can be associated with its index in the vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"../data/LDA/R3-trn-all.txt\") as f:\n",
    "    documents = f.readlines()\n",
    "with open(\"../data/LDA/R3_all_Dictionary.txt\") as f:\n",
    "    vocabulary = f.readlines()\n",
    "documents = np.asarray(documents)\n",
    "num_documents = documents.shape[0]\n",
    "vocabulary = np.asarray(vocabulary)\n",
    "V = vocabulary.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation from Paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization\n",
    "\n",
    "Set everything to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-11-54b6256c51de>, line 20)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-11-54b6256c51de>\"\u001b[1;36m, line \u001b[1;32m20\u001b[0m\n\u001b[1;33m    \u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#count of words with topic_i in document_n \n",
    "document_topic_count = np.zeros((num_documents,num_topics))\n",
    "#sum of all topic-counts, the index is the topic number\n",
    "document_topic_sum = np.zeros((num_topics,))\n",
    "topic_term_count = 0\n",
    "topic_term_sum = 0\n",
    "word_topics = np.zeros((V,num_topics))\n",
    "documents_words = np.zeros(())\n",
    "Z = np.zeros((num_documents,num_topics))\n",
    "\n",
    "#Randomly assigning topics to words\n",
    "for i, word in enumerate(vocabulary):\n",
    "    words_by_topic[i] = np.random.multinomial(1,[1/num_topics]*num_topics)\n",
    "\n",
    "#Loop through words in the document, increment \n",
    "for document in documents:\n",
    "    words = document.split()\n",
    "    for word in words:\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
